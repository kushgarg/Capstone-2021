{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, add\n",
    "from keras.layers.core import  Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31, 1500, 3600)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_01.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_1_2 = []\n",
    "corr_1_3 = []\n",
    "corr_1_4 = []\n",
    "corr_2_3 = []\n",
    "corr_2_4 = []\n",
    "corr_3_4 = []\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "\n",
    "\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_01.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  dataset  corr_1_2  corr_1_3  corr_1_4  corr_2_3  corr_2_4  \\\n",
       "0  ocean_eta_t_2000_01.nc  0.267072 -0.175231 -0.326162 -0.474659 -0.183629   \n",
       "\n",
       "   corr_3_4  \n",
       "0  0.128318  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>corr_1_2</th>\n      <th>corr_1_3</th>\n      <th>corr_1_4</th>\n      <th>corr_2_3</th>\n      <th>corr_2_4</th>\n      <th>corr_3_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ocean_eta_t_2000_01.nc</td>\n      <td>0.267072</td>\n      <td>-0.175231</td>\n      <td>-0.326162</td>\n      <td>-0.474659</td>\n      <td>-0.183629</td>\n      <td>0.128318</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df = pd.DataFrame({\"dataset\":dataset, \"corr_1_2\":corr_1_2,'corr_1_3':corr_1_3,'corr_1_4':corr_1_4,'corr_2_3':corr_2_3,'corr_2_4':corr_2_4,'corr_3_4':corr_3_4}).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape\n",
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(29)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(29)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(29)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(29)]\n",
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_02.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape\n",
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_03.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape\n",
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_04.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape\n",
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(31)]\n",
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_05.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =['C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc']\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_02.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_03.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_04.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_05.nc')\n",
    "# file_path.append('C:/Users/Administrator/OneDrive - The University of Melbourne/capstone/data/OFAM_2017/ocean_eta_t/ocean_eta_t_2000_06.nc')\n",
    "ds = nc4.MFDataset(file_path)\n",
    "eta_t_arr = ds.variables['eta_t'][:]\n",
    "eta_t_arr.shape\n",
    "data1 = eta_t_arr[:,:750,:1800]\n",
    "data2 = eta_t_arr[:,:750,1800:3600]\n",
    "data3 = eta_t_arr[:,750:1500,:1800]\n",
    "data4 = eta_t_arr[:,750:1500,1800:3600]\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    arr = data1[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    arr = data2[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    arr = data3[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    arr = data4[i].data\n",
    "    arr[arr == -32768] = 0\n",
    "data1=[normalize(data1[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data2=[normalize(data2[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data3=[normalize(data3[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data4=[normalize(data4[i,:,:],axis=1,norm='l1') for i in range(30)]\n",
    "data1=np.array(data1)\n",
    "data2=np.array(data2)\n",
    "data3=np.array(data3)\n",
    "data4=np.array(data4)\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_1_2 = pearsonr(data1.reshape(-1),data2.reshape(-1))[0]\n",
    "cor_1_3 = pearsonr(data1.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_1_4 = pearsonr(data1.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_2_3 = pearsonr(data2.reshape(-1),data3.reshape(-1))[0]\n",
    "cor_2_4 = pearsonr(data2.reshape(-1),data4.reshape(-1))[0]\n",
    "cor_3_4 = pearsonr(data3.reshape(-1),data4.reshape(-1))[0]\n",
    "\n",
    "corr_1_2.append(cor_1_2)\n",
    "corr_1_3.append(cor_1_3)\n",
    "corr_1_4.append(cor_1_4)\n",
    "corr_2_3.append(cor_2_3)\n",
    "corr_2_4.append(cor_2_4)\n",
    "corr_3_4.append(cor_3_4)\n",
    "dataset.append('ocean_eta_t_2000_06.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  dataset  corr_1_2  corr_1_3  corr_1_4  corr_2_3  corr_2_4  \\\n",
       "0  ocean_eta_t_2000_01.nc  0.267072 -0.175231 -0.326162 -0.474659 -0.183629   \n",
       "1  ocean_eta_t_2000_02.nc  0.272479 -0.187195 -0.329950 -0.481629 -0.166229   \n",
       "2  ocean_eta_t_2000_03.nc  0.268289 -0.180205 -0.339560 -0.490257 -0.153665   \n",
       "3  ocean_eta_t_2000_04.nc  0.268985 -0.173877 -0.348065 -0.508109 -0.173825   \n",
       "4  ocean_eta_t_2000_05.nc  0.269085 -0.169016 -0.343095 -0.503677 -0.189343   \n",
       "5  ocean_eta_t_2000_06.nc  0.263432 -0.161480 -0.330233 -0.486053 -0.176159   \n",
       "\n",
       "   corr_3_4  \n",
       "0  0.128318  \n",
       "1  0.119218  \n",
       "2  0.116620  \n",
       "3  0.129971  \n",
       "4  0.137465  \n",
       "5  0.137536  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>corr_1_2</th>\n      <th>corr_1_3</th>\n      <th>corr_1_4</th>\n      <th>corr_2_3</th>\n      <th>corr_2_4</th>\n      <th>corr_3_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ocean_eta_t_2000_01.nc</td>\n      <td>0.267072</td>\n      <td>-0.175231</td>\n      <td>-0.326162</td>\n      <td>-0.474659</td>\n      <td>-0.183629</td>\n      <td>0.128318</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ocean_eta_t_2000_02.nc</td>\n      <td>0.272479</td>\n      <td>-0.187195</td>\n      <td>-0.329950</td>\n      <td>-0.481629</td>\n      <td>-0.166229</td>\n      <td>0.119218</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ocean_eta_t_2000_03.nc</td>\n      <td>0.268289</td>\n      <td>-0.180205</td>\n      <td>-0.339560</td>\n      <td>-0.490257</td>\n      <td>-0.153665</td>\n      <td>0.116620</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ocean_eta_t_2000_04.nc</td>\n      <td>0.268985</td>\n      <td>-0.173877</td>\n      <td>-0.348065</td>\n      <td>-0.508109</td>\n      <td>-0.173825</td>\n      <td>0.129971</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ocean_eta_t_2000_05.nc</td>\n      <td>0.269085</td>\n      <td>-0.169016</td>\n      <td>-0.343095</td>\n      <td>-0.503677</td>\n      <td>-0.189343</td>\n      <td>0.137465</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ocean_eta_t_2000_06.nc</td>\n      <td>0.263432</td>\n      <td>-0.161480</td>\n      <td>-0.330233</td>\n      <td>-0.486053</td>\n      <td>-0.176159</td>\n      <td>0.137536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df = pd.DataFrame({\"dataset\":dataset, \"corr_1_2\":corr_1_2,'corr_1_3':corr_1_3,'corr_1_4':corr_1_4,'corr_2_3':corr_2_3,'corr_2_4':corr_2_4,'corr_3_4':corr_3_4}).reset_index(drop=True)\n",
    "df"
   ]
  }
 ]
}